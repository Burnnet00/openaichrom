OS Linux 

Задача состоит в том, чтобы написать приложение на python, которое позволяет пользователю разговаривать с GPT-3.5-turbo - одной из самых мощных языковых моделей на сегодняшний день. 
Приложение должно сохранять историю предыдущих разговоров в памяти (Chroma) и использовать их в Хроме для установки контекста при начале нового разговора. 


Для установки зависимостей приложения необходимо выполнить следующие шаги:

- Установить python версии 3.10 или выше на операционную систему (linux). 
  Для этого можно использовать команду sudo apt install python3.10 или скачать установщик с официального сайта https://www.python.org/downloads/.
- Установить библиотеки, перечисленные в файле requirements.txt, с помощью команды pip install -r requirements.txt. 
  Это установит библиотеки langchain, openai, pandas, tiktoken и google-api-python-client.
- Получить ключ API для доступа к сервису OpenAI. Для этого необходимо зарегистрироваться на сайте https://beta.openai.com/ и получить ключ в формате sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxx. 
  Этот ключ нужно будет указать в файле chain.py в переменной OPENAI_API_KEY.
- Получить ключ шифрования для работы с памятью Chroma. Для этого необходимо использовать команду chroma generate-key, которая сгенерирует ключ в формате xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx. 
  Этот ключ нужно будет указать в файле memory.py в переменной CHROMA_ENCRYPTION_KEY.
- Выбрать хранилище для памяти Chroma. Возможные варианты: файловая система, база данных SQLite, облачный сервис Google Cloud Storage. 
  В зависимости от выбранного хранилища нужно будет указать соответствующие параметры в файле memory.py в переменной CHROMA_STORAGE. 
  Например, для файловой системы нужно указать путь к файлу, для SQLite - путь к базе данных, для Google Cloud Storage - название бакета и путь к файлу.

План :

- Создать цепочку LangChain, которая будет принимать текстовый ввод от пользователя и передавать его в LLM GPT-3.5-turbo через OpenAI API.
- Настроить промт для LLM так, чтобы он использовал историю предыдущих разговоров из памяти Chroma для установки контекста и генерировал текстовый ответ для пользователя.
- Сохранять новые разговоры в памяти Chroma после каждого вызова LLM.
- Создать простой интерфейс пользователя для ввода и вывода текста (например, консольный или веб-интерфейс).

Для решения этой задачи я планирую использовать следующие технологии:

- LangChain - это фреймворк для разработки приложений на основе языковых моделей. Он предоставляет удобный интерфейс для работы с разными LLMs, а также интеграции с другими источниками данных и вычислений. 
LangChain позволяет легко создавать цепочки вызовов LLMs и агентов, которые взаимодействуют со своим окружением. Альтернативой LangChain может быть использование низкоуровневого API OpenAI или других библиотек для работы с LLMs, но это потребует больше кода и сложности.
- OpenAI API - это сервис, который предоставляет доступ к различным языковым моделям, включая GPT-3.5-turbo. OpenAI API является единственным способом использовать GPT-3.5-turbo в своем приложении. 
Альтернативой OpenAI API может быть использование других языковых моделей, которые доступны в открытом доступе или на других платформах, но они могут быть менее мощными или подходящими для задачи.
- Chroma - это библиотека для работы с памятью в приложениях на основе языковых моделей. Она позволяет сохранять и извлекать данные из разных хранилищ, таких как файлы, базы данных или облако. Chroma интегрирована с LangChain и облегчает работу с памятью в цепочках и агентах. 
Альтернативой Chroma может быть использование стандартных средств python для работы с файлами или базами данных, но это потребует больше кода и сложности.



